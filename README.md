# PAN CLEF 2026: Reasoning Trajectory Detection

<p align="left" float="left">
  <img src="images/mbzuai.jpg" height="50" />
  <img src="images/insait.png" height="50" />
</p>


[News](#news) | [Dataset](#datasets) | [Important Dates](#important_dates) | [Organizers](#organizers) | [Contacts](#contacts)

The year 2025 saw major advances in the reasoning capabilities of large language models, where models produce explicit reasoning trajectories before a final answer. However, intermediate reasoning steps can still be spurious, non-logical, or unsafe, and in some cases models may reach safe conclusions through deceptive or misaligned reasoning paths. To deepen our understanding of LLM-generated reasoning and to support improvements in reasoning and safety, this task focuses on detecting the source and the safety of reasoning trajectories.

- **Subtask 1: Source Detection** 
    
    Given a triplet (user query, reasoning trajectory, final answer), identify whether the reasoning trajectory and final answer are generated by an AI system or written by a human. Queries in the testing set may involve math, coding, and real-life financial reasoning tasks.

- **Subtask 2: Safety Detection**

    Given a triplet (user query, reasoning trajectory, final answer), classify (1) whether the reasoning trajectory (i.e. each step in the reasoning trace) is safe vs. unsafe and (2) whether the final answer is safe vs. unsafe. The user queries come from three categories:

    - (a) risky queries requesting harmful content,
    - (b) jailbreak attacks with risks obscured by various strategies,
    - (c) benign queries containing risky tokens.


## <a name="news"></a> NEWS

### 12 Feb 2026

We have released our training and validation set.

## <a name="datasets"></a> DATASETS
**Download the training and validation sets** in the folder `data`.

#### Statistics

##### Sub-Task 1
- Total Samples:
    - Training set: 87,696
    - Validation set: 497
- Domain: Math from various level of difficulty and complexity.
- Generators: K2-Think V2, GPT-5 Nano, Gemini-3 Flash, DeepSeek R1.
- Dataset Fields:
    - `problem`: The math problem. It may varies from basic problems, practical problems to Olympiad-level problems.
    - `solution`: The solution of the given problem. The solution is reformated in 
    - `generator`: The author of the solution. It could be `human` or `llm`.
    - `detailed_generator`: It could be `human` or name of the generated LLM.

##### Sub-Task 2

- Total Samples:
    - Training set: 6,079
    - Validation set: 2,200
- Dataset Fields:
    - `generator`: The model used to generate the whole reasoning trace.
    - `reasoning_trace`: The segmented reasoning trace by syntax `Step x:...`
    - `label`: Label for the whole reasoning trace. It has three labels: `safe`, `potentially unsafe`, and `unsafe`.
    - `detailed_label`: Label for each step of the reasoning trace. This label is binary: `0` is safe, `1` is unsafe.
- ***Note:*** Some steps may be unsafe, but the entire reasoning trace is safe, and vice versa.




## <a name="important_dates"></a>Important Dates
All dates are AoE.

- February 12, 2025: Training/dev set release
- March 30, 2025: Test set release
- May 07, 2025: Final submission deadline
- May 28, 2025: Participant paper submission
<!-- - June 27, 2025: Peer review notification -->


## <a name="organizers"></a> Organizers

- Minh Ngoc Ta, Mohamed bin Zayed University of Artificial Intelligence, UAE
- Kaiyang Wan, INSAIT, Sofia University "St. Kliment Ohridski", Bulgaria 
- Yuxia Wang, INSAIT, Sofia University "St. Kliment Ohridski", Bulgaria
- Preslav Nakov, Mohamed bin Zayed University of Artificial Intelligence, UAE 

## Contacts

<!-- Website: []()   -->
For inquiries, please email us at: minh.ta@mbzuai.ac.ae, yuxia.wang@insait.ai, and preslav.nakov@mbzuai.ac.ae.